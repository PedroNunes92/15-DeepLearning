{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: https://medium.com/@mikesmales/sound-classification-using-deep-learning-8bc2aa1990b7\n",
    "\n",
    "https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/\n",
    "\n",
    "datasets: https://zindi.africa/hackathons\n",
    "\n",
    "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação de pacotes necessários ao Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip search xlrd\n",
    "#!pip install xlrd\n",
    "#!pip search librosa\n",
    "#!pip install librosa\n",
    "#!pip search sndfile\n",
    "#!pip install sndfile -U\n",
    "#!conda search sndfile\n",
    "#apt-get install libsndfile1\n",
    "!pip install wavefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras; \n",
    "import tensorflow as tf; \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import struct\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Versão Keras :\" , keras.__version__)\n",
    "print(\"Versão Tensorflow :\" , tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir vamos investigar exemplos de criação de tensores com dados reais\n",
    "\n",
    "Os dados que você manipulará quase sempre cairão em uma das seguintes categorias:\n",
    "\n",
    "* Vector data:\n",
    "    * 2D tensores com formato (amostras, características)\n",
    "\n",
    "* Séries temporais ou sequência\n",
    "    * data—3D tensores com formato (amostras, passos temporais , características)\n",
    "* Images—4D \n",
    "    * tensores com formato \n",
    "        * (amostras,altura,largura,canais) \n",
    "        * (amostras,canais, altura,largura)\n",
    "* Video —5D \n",
    "    * tensores com formato \n",
    "        * (amostras, frames, altura, largura, canais) \n",
    "        * (amostras, frames, canais, altura,largura)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferentes formatos de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"0d Tensor (scalar)\")\n",
    "\n",
    "x = np.array(12)\n",
    "print(x)\n",
    "print(x.ndim)\n",
    "\n",
    "print(\"1d tensor\")\n",
    "\n",
    "x = np.array([12, 3, 6, 14])\n",
    "print(x)\n",
    "print(x.ndim)\n",
    "    \n",
    "print(\"2d tensor\")\n",
    "\n",
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "             [6, 79, 3, 35, 1],\n",
    "             [7, 80, 4, 36, 2]])\n",
    "\n",
    "print(x)\n",
    "print(x.ndim)\n",
    "\n",
    "print(\"3d tensor\")\n",
    "\n",
    "x = np.array(  [[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "               [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "               [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação de datasets estruturados em colunas\n",
    "\n",
    "\n",
    "* Pandas pode ser usado para representar colunas preditoras e coluna a ser predita\n",
    "\n",
    "* Exemplo abaixo mostra colunas caracterizando resultados de exames de diversos pacientes e diagnostico para SARS-Cov2 (https://www.kaggle.com/einsteindata4u/covid19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataset4.xlsx', encoding='utf8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação de imagens\n",
    "\n",
    "* Imagens são compostas por uma matriz de pixel\n",
    "\n",
    "* Cada pixel pode ser definido como um ou mais valores\n",
    "    * Imagens em tom de cinza possuem apenas um valor de pixel\n",
    "    * Imagens codificadas como RGB (possuem 3 canais)\n",
    "    \n",
    "* A representação pode ser feita por uma matriz de 4 dimensões\n",
    "    * Altura\n",
    "    * Largura\n",
    "    * Canal de cor\n",
    "    * Amostras\n",
    "\n",
    "* Há dois padrões para representar imagens como vetores:\n",
    "\n",
    "    * channel first: dimensão de canais de cor aparece primeiro\n",
    "        (amostras, canais de cor, altura, lagura)\n",
    "    * channel last: dimensão de canais de cor aparece por último (padrão tensorflow - Keras)\n",
    "        (amostras, altura, lagura, canais de cor)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo cats and dogs\n",
    "https://www.kaggle.com/c/dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../dogsCatsDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"../dogsCatsDB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"../dogsCatsDB/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"../dogsCatsDB/\"\n",
    "train_dir = \"train\"\n",
    "path = os.path.join(main_dir,train_dir)\n",
    "\n",
    "# Percorre todos os arquivos do diretório\n",
    "for p in os.listdir(path):\n",
    "    # Categoria é obtida a partir do nome do arquivo\n",
    "    category = p.split(\".\")[0]\n",
    "    \n",
    "    img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "    new_img_array = cv2.resize(img_array, dsize=(80, 80))\n",
    "    plt.imshow(new_img_array,cmap=\"gray\")\n",
    "    break\n",
    "print(new_img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "convert = lambda category : int(category == 'dog')\n",
    "\n",
    "# Percorre os arquivos no diretório de imagens para treinamento\n",
    "\n",
    "def create_test_data(path):\n",
    "    for p in os.listdir(path):\n",
    "\n",
    "        # categoria da imagem é definida pelo nome do arquivo\n",
    "        category = p.split(\".\")[0]\n",
    "\n",
    "        # define categoria como 0 ou 1\n",
    "        category = convert(category)\n",
    "        \n",
    "        # Abre a imagem usando opencv em escala de cinza\n",
    "        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Redimensionamento para 80 x 80 pixels\n",
    "        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n",
    "        \n",
    "        X.append(new_img_array)\n",
    "        y.append(category)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"../dogsCatsDB/train\"\n",
    "\n",
    "create_test_data(path)\n",
    "\n",
    "print(np.array(X).shape)\n",
    "print(np.array(y).shape)\n",
    "\n",
    "X = np.array(X).reshape(-1, 80,80,1)\n",
    "y = np.array(y)\n",
    "\n",
    "print(np.array(X).shape)\n",
    "print(np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ../dogsCatsDB/test1 | wc -l\n",
    "\n",
    "#!cat ../dogsCatsDB/sampleSubmission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo asas de abelhas\n",
    "\n",
    "* Utilizaremos esses dados como exercício para algumas aulas\n",
    "\n",
    "* Segue papers de referência do desafio:\n",
    "\n",
    "https://www.sciencedirect.com/science/article/abs/pii/S1574954113001222\n",
    "https://www.sciencedirect.com/science/article/pii/S0168169915000873\n",
    "\n",
    "* Dados:\n",
    "* https://f-leno.github.io/downloads/WingImagesAReference.zip\n",
    "* https://f-leno.github.io/downloads/WingImagesEvaluatingClassification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/silvio/git/datasets/bees/wingsEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"/home/silvio/git/datasets/bees/\"\n",
    "train_dir = \"wingsEval\"\n",
    "path = os.path.join(main_dir,train_dir)\n",
    "\n",
    "# Percorre todos os arquivos do diretório\n",
    "for p in os.listdir(path):\n",
    "    # Categoria é obtida a partir do nome do arquivo\n",
    "    category = p.split(\" \")[0]\n",
    "    \n",
    "    img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "    new_img_array = cv2.resize(img_array, dsize=(320, 320))\n",
    "    plt.imshow(new_img_array,cmap=\"gray\")\n",
    "    break\n",
    "print(new_img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/silvio/git/datasets/bees/wingsEval\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "# Percorre os arquivos no diretório de imagens para treinamento\n",
    "def create_test_data(path):\n",
    "    for p in os.listdir(path):\n",
    "\n",
    "        # categoria da imagem é definida pelo nome do arquivo\n",
    "        category = p.split(\" \")[0]\n",
    "        \n",
    "        # Abre a imagem usando opencv em escala de cinza\n",
    "        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Redimensionamento para 80 x 80 pixels\n",
    "        new_img_array = cv2.resize(img_array, dsize=(320, 320))\n",
    "        \n",
    "        X.append(new_img_array)\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path= \"../dogsCatsDB/train\"\n",
    "path=\"/home/silvio/git/datasets/bees/wingsEval\"\n",
    "\n",
    "create_test_data(path)\n",
    "\n",
    "print(np.array(X).shape)\n",
    "print(np.array(y).shape)\n",
    "\n",
    "X = np.array(X).reshape(-1, 320,320,1)\n",
    "y = np.array(y)\n",
    "\n",
    "print(np.array(X).shape)\n",
    "print(np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "yy = le.fit_transform(y)\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação de Sequência e Séries Temporais\n",
    "\n",
    "* Alguns fenômenos são representados como uma sequência de acontecimentos (Exemplos)\n",
    "    * Variação de preço de ações\n",
    "    * Sequência de palavras\n",
    "    * Crescimento de animais\n",
    "\n",
    "* Uma estratégia é representar a sequência de ações como uma sequência de colunas,\n",
    "  e repetir as colunas para um número fixo de sequências\n",
    "\n",
    "* Outra estratégia é representar cada sequência como uma linha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estratégias de Representação\n",
    "\n",
    "### Preços de ações. \n",
    "    * A cada minuto, armazenamos o preço atual das ações, o preço mais alto do último minuto e o preço mais baixo do último minuto. \n",
    "    * Cada minuto é codificado como um vetor 3D, um dia inteiro de negociação é codificado como um tensor 2D de forma (390, 3) (há 390 minutos em um dia de negociação)\n",
    "    * dados de 250 dias podem ser armazenados em um tensor de forma 3D (250, 390,3). \n",
    "\n",
    "### Twitter\n",
    "\n",
    "    * Um conjunto de dados de tweets, em que codificamos cada tweet como uma sequência de 280 caracteres de um alfabeto de 128 caracteres únicos. \n",
    "\n",
    "    * Nesta configuração, cada caractere pode ser codificado como um vetor binário de tamanho 128 (um vetor com todos os zeros, exceto por uma entrada 1 no índice correspondente ao caractere).\n",
    "\n",
    "    * cada tweet pode ser codificado como um tensor de forma 2D (280, 128) \n",
    "\n",
    "    * um conjunto de dados de 1 milhão de tweets pode ser armazenado em um tensor de forma (1000000, 280, 128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "url=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
    "df2=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Os dados a seguir referem-se a uma base de teste que mostra a quantidade de passageiros por mês de uma empresa área\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)\n",
    "df2.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A quantidade de passageiros cresce ao longo do tempo, porém há alguns padrões em meses específicos do ano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando os passos temporais em duas colunas\n",
    "\n",
    "* A coluna 0 representa o mês corrente e a segunda coluna o próximo mês\n",
    "* Uma regressão pode ser usada para prever o próximo número de passageiros de um mês para outro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df2['Passengers']\n",
    "\n",
    "col20=dataset[slice(1,dataset.shape[0])]\n",
    "col10=dataset[slice(0,dataset.shape[0]-1)]\n",
    "\n",
    "col1 = pd.Series([0])\n",
    "col2 = pd.Series([dataset[0]])\n",
    "\n",
    "col1=col1.append(col10)\n",
    "col2=col2.append(col20)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'t-1':col1.values,\n",
    "                   't':col2.values})\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O número de elementos na sequência pode ser alterado de forma a expressar corretamente o evento\n",
    "* Nesse caso poderia ser usado 3 meses para detectar o quarto mês por exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df2['Passengers']\n",
    "\n",
    "col30=dataset[slice(2,dataset.shape[0])]\n",
    "col20=dataset[slice(1,dataset.shape[0]-1)]\n",
    "col10=dataset[slice(0,dataset.shape[0]-2)]\n",
    "\n",
    "col1 = pd.Series([0])\n",
    "col2 = pd.Series([dataset[0]])\n",
    "col3 = pd.Series([dataset[1]])\n",
    "\n",
    "col1=col1.append(col10)\n",
    "col2=col2.append(col20)\n",
    "col3=col3.append(col30)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'t-2':col1.values,\n",
    "                   't-1':col2.values,\n",
    "                   't':col3.values})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../datasets/sound/UrbanSound8K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação de audio\n",
    "\n",
    "* Esse dataset (https://urbansounddataset.weebly.com/urbansound8k.html) contém 8732 amostras de audio das seguintes categorias: \n",
    "\n",
    "    * Air Conditioner\n",
    "    * Car Horn\n",
    "    * Children Playing\n",
    "    * Dog bark\n",
    "    * Drilling\n",
    "    * Engine Idling\n",
    "    * Gun Shot\n",
    "    * Jackhammer\n",
    "    * Siren\n",
    "    * Street Music\n",
    "\n",
    "* Um exemplo de áudio é fornecido em um formato digita (arquivo .wav) de alguns segundos, a partir dessa amostra o sistema deve classificar a amostra de acordo com uma das categorias mencionadas\n",
    "\n",
    "\n",
    "* Amostras de som são arquivos de áudio digital no formato .wav. As ondas sonoras são digitalizadas em intervalos discretos (sampling rate)\n",
    "\n",
    "\n",
    "* Cada amostra é a amplitude da onda em um intervalo de tempo específico, onde a profundidade do bit determina o quão detalhada a amostra também será conhecida como faixa dinâmica do sinal\n",
    "\n",
    "\n",
    "* Dessa forma, um som é representado de forma simples, como um conjunto de valores ao longo de um intervalo de tempo fixo\n",
    "\n",
    "\n",
    "* As amostras podem ter valores diversos para: \n",
    "    * Audio Channels\n",
    "    * Sample rate\n",
    "    * Bit-depth\n",
    "\n",
    "\n",
    "* Nesse exemplo, foi usada a biblioteca librosa que fas o seguinte pre-processamento:\n",
    "\n",
    "    * Converte a taxa de amostragem em 22,05 KHz\n",
    "    * Normaliza os dados para que os valores de profundidade de bits variem entre -1 e 1 \n",
    "    * Nivelam os canais de áudio em mono "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavFileHelper():\n",
    "    \n",
    "    def read_file_properties(self, filename):\n",
    "\n",
    "        wave_file = open(filename,\"rb\")\n",
    "        \n",
    "        riff = wave_file.read(12)\n",
    "        fmt = wave_file.read(36)\n",
    "        \n",
    "        num_channels_string = fmt[10:12]\n",
    "        num_channels = struct.unpack('<H', num_channels_string)[0]\n",
    "\n",
    "        sample_rate_string = fmt[12:16]\n",
    "        sample_rate = struct.unpack(\"<I\",sample_rate_string)[0]\n",
    "        \n",
    "        bit_depth_string = fmt[22:24]\n",
    "        bit_depth = struct.unpack(\"<H\",bit_depth_string)[0]\n",
    "\n",
    "        return (num_channels, sample_rate, bit_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfilehelper = WavFileHelper()\n",
    "\n",
    "metadata = pd.read_csv('../datasets/sound/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "audiodata = []\n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath('../datasets/sound/UrbanSound8K/audio/'),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    data = wavfilehelper.read_file_properties(file_name)\n",
    "    #data = WaveReader(file_name)\n",
    "    audiodata.append(data)\n",
    "\n",
    "# Convert into a Panda dataframe\n",
    "audiodf = pd.DataFrame(audiodata, columns=['num_channels','sample_rate','bit_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiodf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../datasets/sound/UrbanSound8K/metadata/UrbanSound8K.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../datasets/sound/UrbanSound8K/audio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2 = pd.read_csv( '../datasets/sound/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        #print(mfccs)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = '../datasets/sound/UrbanSound8K/audio/'\n",
    "\n",
    "metadata2 = pd.read_csv( '../datasets/sound/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "metadata = metadata2[:5]\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converte sinais de audio e categorias para X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representação de texto\n",
    "\n",
    "* Um texto pode ser representado como cada parágrafo sendo uma linha no dataset e cada palavras uma coluna\n",
    "\n",
    "* Palavras podem ser vetorizadas para possuirem uma representação numérica\n",
    "\n",
    "* Uma estratégia é associar um número para cada palavra que pode aparecer no texto, e trocar todas as palavras do texto pelo número correspondente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "# define the document\n",
    "text = 'The quick brown fox jumped over the lazy dog.'\n",
    "# tokenize the document\n",
    "result = text_to_word_sequence(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "# define the document\n",
    "text = 'The quick brown fox jumped over the lazy dog.'\n",
    "\n",
    "# estimate the size of the vocabulary\n",
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "\n",
    "# integer encode the document\n",
    "result = one_hot(text, round(vocab_size*1.3))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url=\"https://raw.githubusercontent.com/vineetdhanawat/twitter-sentiment-analysis/master/datasets/Sentiment%20Analysis%20Dataset.csv\"\n",
    "#df2=pd.read_csv(url)\n",
    "#df2\n",
    "\n",
    "df2=pd.read_csv(\"data.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
